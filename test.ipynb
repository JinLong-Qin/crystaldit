{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fd486a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tokenizers.normalizers import BertNormalizer\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from transformers import AutoModel\n",
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'alpha.hf-mirror.com'\n",
    "# HUGGINGFACE_CO_RESOLVE_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0162a6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /home/fall/.cache/huggingface/hub/models--m3rg-iitd--matscibert/snapshots/ced9d8f5f208712c4a90f98a246fe32155b29995 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocab size: 31090\n",
      "Model loaded OK: BertModel\n"
     ]
    }
   ],
   "source": [
    "local_path = '/home/fall/.cache/huggingface/hub/models--m3rg-iitd--matscibert/snapshots/ced9d8f5f208712c4a90f98a246fe32155b29995'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_path, model_max_length=512)\n",
    "text_model = AutoModel.from_pretrained(local_path)\n",
    "print(\"Tokenizer vocab size:\", len(tokenizer))\n",
    "print(\"Model loaded OK:\", text_model.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc225937",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@File         :hf_download.py\n",
    "@Description  :Download huggingface models and datasets from mirror site.\n",
    "@Author       :Xiaojian Yuan\n",
    "\"\"\"\n",
    " \n",
    " \n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    " \n",
    "# Check if huggingface_hub is installed, if not, install it\n",
    "try:\n",
    "    import huggingface_hub\n",
    "except ImportError:\n",
    "    print(\"Install huggingface_hub.\")\n",
    "    os.system(\"pip install -U huggingface_hub\")\n",
    " \n",
    " \n",
    "parser = argparse.ArgumentParser(description=\"HuggingFace Download Accelerator Script.\")\n",
    "parser.add_argument(\n",
    "    \"--model\",\n",
    "    \"-M\",\n",
    "    default=None,\n",
    "    type=str,\n",
    "    help=\"model name in huggingface, e.g., baichuan-inc/Baichuan2-7B-Chat\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--token\",\n",
    "    \"-T\",\n",
    "    default=None,\n",
    "    type=str,\n",
    "    help=\"hugging face access token for download meta-llama/Llama-2-7b-hf, e.g., hf_***** \",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--include\",\n",
    "    default=None,\n",
    "    type=str,\n",
    "    help=\"Specify the file to be downloaded\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--exclude\",\n",
    "    default=None,\n",
    "    type=str,\n",
    "    help=\"Files you don't want to download\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--dataset\",\n",
    "    \"-D\",\n",
    "    default=None,\n",
    "    type=str,\n",
    "    help=\"dataset name in huggingface, e.g., zh-plus/tiny-imagenet\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--save_dir\",\n",
    "    \"-S\",\n",
    "    default=None,\n",
    "    type=str,\n",
    "    help=\"path to be saved after downloading.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--use_hf_transfer\", default=True, type=eval, help=\"Use hf-transfer, default: True\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--use_mirror\", default=True, type=eval, help=\"Download from mirror, default: True\"\n",
    ")\n",
    " \n",
    "args = parser.parse_args()\n",
    " \n",
    "if args.use_hf_transfer:\n",
    "    # Check if hf_transfer is installed, if not, install it\n",
    "    try:\n",
    "        import hf_transfer\n",
    "    except ImportError:\n",
    "        print(\"Install hf_transfer.\")\n",
    "        os.system(\"pip install -U hf-transfer -i https://pypi.org/simple\")\n",
    "    # Enable hf-transfer if specified\n",
    "    os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
    "    print(\"export HF_HUB_ENABLE_HF_TRANSFER=\", os.getenv(\"HF_HUB_ENABLE_HF_TRANSFER\"))\n",
    " \n",
    " \n",
    "if args.model is None and args.dataset is None:\n",
    "    print(\n",
    "        \"Specify the name of the model or dataset, e.g., --model baichuan-inc/Baichuan2-7B-Chat\"\n",
    "    )\n",
    "    sys.exit()\n",
    "elif args.model is not None and args.dataset is not None:\n",
    "    print(\"Only one model or dataset can be downloaded at a time.\")\n",
    "    sys.exit()\n",
    " \n",
    "if args.use_mirror:\n",
    "    # Set default endpoint to mirror site if specified\n",
    "    os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "    print(\"export HF_ENDPOINT=\", os.getenv(\"HF_ENDPOINT\"))  # https://hf-mirror.com\n",
    " \n",
    " \n",
    "if args.token is not None:\n",
    "    token_option = \"--token %s\" % args.token\n",
    "else:\n",
    "    token_option = \"\"\n",
    " \n",
    "if args.include is not None:\n",
    "    include_option = \"--include %s\" % args.include\n",
    "else:\n",
    "    include_option =  \"\"\n",
    "     \n",
    "if args.exclude is not None:\n",
    "    exclude_option = \"--exclude %s\" % args.exclude\n",
    "else:\n",
    "    exclude_option = \"\"\n",
    "     \n",
    "     \n",
    "if args.model is not None:\n",
    "    model_name = args.model.split(\"/\")\n",
    "    save_dir_option = \"\"\n",
    "    if args.save_dir is not None:\n",
    "        if len(model_name) > 1:\n",
    "            save_path = os.path.join(\n",
    "                args.save_dir, \"models--%s--%s\" % (model_name[0], model_name[1])\n",
    "            )\n",
    "        else:\n",
    "            save_path = os.path.join(\n",
    "                args.save_dir, \"models--%s\" % (model_name[0])\n",
    "            )\n",
    "        save_dir_option = \"--local-dir %s\" % save_path\n",
    " \n",
    "    download_shell = (\n",
    "        \"huggingface-cli download %s %s %s --local-dir-use-symlinks False --resume-download %s %s\"\n",
    "        % (token_option, include_option, exclude_option, args.model, save_dir_option)\n",
    "    )\n",
    "    os.system(download_shell)\n",
    " \n",
    "elif args.dataset is not None:\n",
    "    dataset_name = args.dataset.split(\"/\")\n",
    "    save_dir_option = \"\"\n",
    "    if args.save_dir is not None:\n",
    "        if len(dataset_name) > 1:\n",
    "            save_path = os.path.join(\n",
    "                args.save_dir, \"datasets--%s--%s\" % (dataset_name[0], dataset_name[1])\n",
    "            )\n",
    "        else:\n",
    "            save_path = os.path.join(\n",
    "                args.save_dir, \"datasets--%s\" % (dataset_name[0])\n",
    "            )\n",
    "        save_dir_option = \"--local-dir %s\" % save_path\n",
    " \n",
    "    download_shell = (\n",
    "        \"huggingface-cli download %s %s %s --local-dir-use-symlinks False --resume-download  --repo-type dataset %s %s\"\n",
    "        % (token_option, include_option, exclude_option, args.dataset, save_dir_option)\n",
    "    )\n",
    "    os.system(download_shell)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crystaldit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
